import os
import json
import asyncio
import re
import ast
import sys
import subprocess
import tempfile
import platform
from openai import AsyncOpenAI
from dotenv import load_dotenv

# è‡ªåŠ¨ä¿®æ­£ Windows ç³»ç»Ÿä»£ç†
for key in ["http_proxy", "https_proxy", "HTTP_PROXY", "HTTPS_PROXY"]:
    proxy = os.environ.get(key)
    if proxy and not proxy.startswith("http"):
        print(f"Fixing proxy format: {key}={proxy}")
        os.environ[key] = f"http://{proxy}"

load_dotenv()

client = AsyncOpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com",
    timeout=60.0,
    max_retries=2
)

# ==========================================
# 1. æ ¸å¿ƒ Prompts
# ==========================================

SYSTEM_CLASSIFIER = """ä½ æ˜¯ä¸€ä¸ªæ„å›¾è¯†åˆ«ä¸“å®¶ã€‚
ä»»åŠ¡ï¼šåˆ†æç”¨æˆ·è¾“å…¥ï¼Œåˆ†ç±»ä¸ºï¼š
1. **task**: æè¿°æ€§éœ€æ±‚ï¼ˆå¦‚â€œå†™ä¸ªæ¸¸æˆâ€ã€â€œå¼€å‘ç½‘ç«™â€ã€â€œæ•°æ®åˆ†æè„šæœ¬â€ï¼‰ã€‚
2. **problem**: ç®—æ³•é¢˜ç›®ï¼ˆå«IOæ ¼å¼ã€æ ·ä¾‹ã€æ—¶é—´é™åˆ¶ï¼‰ã€‚
3. **code**: ç”¨æˆ·æä¾›äº†å®Œæ•´ä»£ç è¯·æ±‚ä¿®å¤ã€‚

è¾“å‡ºJSON: {"type": "task"|"problem"|"code", "language": "python"|"cpp", "has_code_snippet": bool}
"""


def get_explainer_prompt(category):
    latex_rule = "3. **å…¬å¼æ ¼å¼å¼ºåˆ¶**ï¼šè¡Œå†…å…¬å¼å¿…é¡»ç”¨å•ç¾å…ƒç¬¦å·åŒ…è£¹ï¼ˆå¦‚ $E=mc^2$ï¼‰ï¼Œç‹¬ç«‹å…¬å¼å—ç”¨åŒç¾å…ƒç¬¦å·ï¼ˆ$$...$$ï¼‰ã€‚ä¸¥ç¦ä½¿ç”¨ \\( ... \\) æˆ–ç›´æ¥ä½¿ç”¨å°æ‹¬å·ã€‚"

    if category == "task":
        return f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±æŠ€æœ¯æ–‡æ¡£å·¥ç¨‹å¸ˆã€‚è¯·ç”Ÿæˆä¸€ä»½ JSON æ ¼å¼çš„å·¥ç¨‹æ¶æ„æ–‡æ¡£ã€‚
è¾“å‡ºJSON: {{"simple": "Markdownæ–‡æœ¬", "academic": "Markdownæ–‡æœ¬"}}
å†…å®¹è¦æ±‚ï¼š
1. simple: ä½¿ç”¨ç”ŸåŠ¨æ¯”å–»è§£é‡Šç¨‹åºè¿è¡Œæµç¨‹ï¼ˆå¦‚â€œèˆå°â€ã€â€œæ¼”å‘˜â€ï¼‰ã€‚
2. academic: ç±»ä¼¼ README.mdï¼ŒåŒ…å«æŠ€æœ¯æ ˆã€æ¨¡å—åˆ’åˆ†ã€å…³é”®ç±»è®¾è®¡ã€‚
{latex_rule}
"""
    else:
        return f"""ä½ æ˜¯ä¸€ä¸ªè®¡ç®—æœºç§‘å­¦é‡‘ç‰Œè®²å¸ˆã€‚è¯·ç”Ÿæˆä¸€ä»½ JSON æ ¼å¼çš„ç®—æ³•è§£ææŠ¥å‘Šã€‚
è¾“å‡ºJSON: {{"simple": "Markdownæ–‡æœ¬", "academic": "Markdownæ–‡æœ¬"}}
å†…å®¹è¦æ±‚ï¼š
1. simple: ä½¿ç”¨é€šä¿—æ¯”å–»è§£é‡Šç®—æ³•æµç¨‹ã€‚
2. academic: åŒ…å«ç®—æ³•å®šä¹‰ã€çŠ¶æ€è½¬ç§»ã€ä¸¥è°¨çš„æ—¶ç©ºå¤æ‚åº¦åˆ†æã€‚
{latex_rule}
"""
def enforce_architecture_lock(original_code, new_code, design_blueprint):
    """
    çœŸæ­£çš„æ¶æ„é”ï¼šåŸºäºASTæ£€æŸ¥æ ¸å¿ƒå‡½æ•°åå’Œç±»åæ˜¯å¦è¢«ç¯¡æ”¹ã€‚
    """
    try:
        tree_orig = ast.parse(original_code)
        tree_new = ast.parse(new_code)
        
        # æå–å…³é”®ç­¾å (FunctionDef, ClassDef)
        def get_signatures(tree):
            return {node.name for node in ast.walk(tree) if isinstance(node, (ast.FunctionDef, ast.ClassDef))}
        
        orig_sigs = get_signatures(tree_orig)
        new_sigs = get_signatures(tree_new)
        
        # 1. åˆšæ€§çº¦æŸï¼šåŸæœ‰çš„æ ¸å¿ƒæ¥å£å¿…é¡»å­˜åœ¨
        missing = orig_sigs - new_sigs
        if missing:
            return False, f"æ¶æ„é”è¿è§„ï¼šæ£€æµ‹åˆ°æ ¸å¿ƒæ¥å£ä¸¢å¤± {missing}ï¼Œæ‹’ç»åˆå…¥ã€‚"
            
        # 2. è“å›¾çº¦æŸï¼šå¦‚æœè“å›¾è§„å®šäº†ç®—æ³•ç±»å‹ï¼ˆå¦‚å¿…é¡»ç”¨DPï¼‰ï¼Œè¿™é‡Œå¯ä»¥åšæ›´æ·±çš„æ£€æŸ¥
        # (ç®€å•å®ç°å¯ä»¥æ˜¯æ£€æŸ¥æ˜¯å¦å¼•å…¥äº†éæ³•åº“ï¼Œæˆ–è€…é€’å½’æ·±åº¦ç­‰)
        
        return True, "æ¶æ„ä¸€è‡´"
    except Exception as e:
        return False, f"ä»£ç è§£æå¤±è´¥ï¼Œè§†ä¸ºè¿è§„: {e}"

# åœ¨ Review ç¯èŠ‚è°ƒç”¨ï¼š
# is_valid, msg = enforce_architecture_lock(old_code, current_code, approved_design)
# if not is_valid:
#     score = 0  # å¼ºåˆ¶æ‰“åˆ†å½’é›¶
#     critique = f"**æ¶æ„é”è§¦å‘**ï¼š{msg}ã€‚è¯·æ¢å¤åŸæœ‰ç»“æ„ï¼"

SYSTEM_REVERSE_ARCHITECT = """ä½ æ˜¯ä¸€ä¸ªä»£ç é€†å‘åˆ†æä¸“å®¶ã€‚
ä»»åŠ¡ï¼šé˜…è¯»ç”¨æˆ·æä¾›çš„ä»£ç ï¼Œæå–å…¶æ ¸å¿ƒæ¶æ„è®¾è®¡ã€‚
è¾“å‡ºJSON:
{
    "algorithm": "è¯†åˆ«å‡ºçš„ç®—æ³•",
    "data_structures": "ä½¿ç”¨çš„æ ¸å¿ƒæ•°æ®ç»“æ„",
    "headers": "ä»£ç ä¸­å¼•ç”¨çš„å…³é”®å¤´æ–‡ä»¶",
    "complexity": "å½“å‰ä»£ç çš„æ—¶ç©ºå¤æ‚åº¦",
    "blueprint": "ä»£ç æ ¸å¿ƒé€»è¾‘æ‘˜è¦"
}
"""

SYSTEM_FEASIBILITY_ANALYST = """ä½ æ˜¯ä¸€ä¸ªç®—æ³•å¯è¡Œæ€§è¯„ä¼°ä¸“å®¶ã€‚
ä»»åŠ¡ï¼šåˆ¤æ–­ç”¨æˆ·ä»£ç çš„ã€æ ¸å¿ƒç®—æ³•æ€è·¯ã€‘æ˜¯å¦èƒ½è§£å†³é—®é¢˜ã€‚

**åˆ¤å®šæ ‡å‡†ï¼ˆTolerance Policyï¼‰**ï¼š
1. **å¿…é¡»é€šè¿‡ (Pass)**ï¼š
   - ç®—æ³•ç±»å‹æ­£ç¡®ä¸”å¤æ‚åº¦åœ¨å¯æ¥å—èŒƒå›´å†…ã€‚
   - åªè¦æ€è·¯å¯¹ï¼Œå³ä½¿æœ‰Bugã€æ ¼å¼é”™è¯¯æˆ–æ¼äº†ç©ºè¡Œï¼Œä¹Ÿ**å¿…é¡»åˆ¤ Pass**ã€‚
2. **æ‹’ç» (Fail)**ï¼š
   - ç®—æ³•å®Œå…¨é”™è¯¯ï¼ˆå¦‚è´ªå¿ƒè§£åŠ¨æ€è§„åˆ’ï¼‰ã€‚
   - å¤æ‚åº¦ä¸¥é‡è¶…æ ‡ï¼ˆå¦‚ï¼šN=100æ—¶ç”¨äº† O(2^N) é€’å½’ï¼‰ã€‚

è¾“å‡ºJSON:
{
    "pass": true/false,
    "reason": "ç®€è¿°ç†ç”±ã€‚",
    "recommendation": "å¦‚æœ Failï¼Œæ¨èæ”¹ç”¨ä»€ä¹ˆç®—æ³•ï¼ˆå¦‚ï¼š'å»ºè®®æ”¹ç”¨åŠ¨æ€è§„åˆ’'ï¼‰ã€‚"
}
"""


def get_architect_prompt(recommendation=None):
    base = """ä½ æ˜¯ä¸€ä¸ªé«˜çº§ç³»ç»Ÿæ¶æ„å¸ˆã€‚
ä»»åŠ¡ï¼šè®¾è®¡æŠ€æœ¯æ–¹æ¡ˆã€‚**ä¸è¦å†™ä»£ç **ã€‚
è¾“å‡ºJSON: {"algorithm": "...", "data_structures": "...", "headers": "...", "complexity": "...", "blueprint": "..."}"""

    if recommendation:
        return f"{base}\n\n**æœ€é«˜æŒ‡ä»¤**ï¼šä¹‹å‰çš„æ–¹æ¡ˆå› æ€§èƒ½é—®é¢˜è¢«å¦å†³ã€‚**ä½ å¿…é¡»é‡‡çº³ä»¥ä¸‹å»ºè®®**ï¼š\n{recommendation}"
    return base


SYSTEM_ARCHITECT_REVIEWER = """ä½ æ˜¯ä¸€ä¸ªç®—æ³•è®¾è®¡å®¡æŸ¥å‘˜ã€‚
è¾“å‡ºJSON: {"pass": true/false, "critique": "..."}
"""


# V10.22: åŠ¨æ€ Coder Promptï¼ŒåŒºåˆ†å·¥ç¨‹ä»»åŠ¡å’Œç®—æ³•é¢˜
def get_coder_prompt(category, design_plan=None, language="cpp"):
    lang_specific = ""
    if language == "python":
        lang_specific = "3. **è¯­è¨€å¼ºåˆ¶**: å¿…é¡»ä½¿ç”¨ **Python 3** (if __name__ == '__main__':)ã€‚"
    else:
        lang_specific = "3. **è¯­è¨€å¼ºåˆ¶**: å¿…é¡»ä½¿ç”¨ **C++** (å«mainå‡½æ•°, å¿…é¡»åŒ…å«å¿…è¦çš„å¤´æ–‡ä»¶)ã€‚"

    # å·®å¼‚åŒ–çº¦æŸ
    io_constraint = ""
    if category == "task":
        io_constraint = """
4. **å·¥ç¨‹äº¤äº’æ¨¡å¼ (Interactive Mode)**ï¼š
   - **å…è®¸å¹¶é¼“åŠ±**è¾“å‡ºå‹å¥½çš„æç¤ºä¿¡æ¯ï¼ˆå¦‚ "Press Enter to start", "Game Over"ï¼‰ã€‚
   - ä»£ç åº”å…·æœ‰è‰¯å¥½çš„æ¨¡å—åŒ–ç»“æ„ã€‚
   - éœ€è€ƒè™‘ä»£ç çš„å¥å£®æ€§å’Œç”¨æˆ·ä½“éªŒã€‚
"""
    else:
        io_constraint = """
4. **OJ æ´ç™–æ¨¡å¼ (Silent Mode)**ï¼š
   - **ä¸¥ç¦**è¾“å‡ºä»»ä½•æç¤ºè¯­ï¼ˆå¦‚ "è¯·è¾“å…¥N:", "ç»“æœæ˜¯:"ï¼‰ã€‚
   - åªè¾“å‡ºé¢˜ç›®è¦æ±‚çš„**çº¯æ•°æ®**ã€‚
   - ä¸¥æ ¼éµå®ˆè¾“å…¥è¾“å‡ºæ ¼å¼ï¼Œå¤šä¸€ä¸ªç©ºæ ¼éƒ½å¯èƒ½å¯¼è‡´åˆ¤é¢˜å¤±è´¥ã€‚
"""

    base = f"""
**ä¸¥æ ¼çº¦æŸ**ï¼š
1. **å¿…é¡»åŒ…å«è¯¦ç»†çš„ä¸­æ–‡æ³¨é‡Š**ã€‚
2. **åªè¾“å‡ºä¸€ä¸ª** Markdown ä»£ç å—ã€‚
{lang_specific}
{io_constraint}
"""
    if design_plan:
        return f"""ä½ æ˜¯ä¸€ä¸ªæ‰§è¡ŒåŠ›æå¼ºçš„ ACM/å·¥ç¨‹é€‰æ‰‹ã€‚
{base}
**æœ€é«˜æŒ‡ä»¤ï¼ˆæ¶æ„é”ï¼‰**ï¼š
ä½ å¿…é¡»**ä¸¥æ ¼æ‰§è¡Œ**ä»¥ä¸‹æ¶æ„ï¼š
ã€ç®—æ³•/æ¨¡å—ã€‘: {design_plan.get('algorithm', 'æœªæŒ‡å®š')}
ã€æ•°æ®ç»“æ„ã€‘: {design_plan.get('data_structures', 'æœªæŒ‡å®š')}
ã€æ­¥éª¤/è“å›¾ã€‘: {design_plan.get('blueprint', 'æœªæŒ‡å®š')}

**ä¸¥ç¦æ“…è‡ªæ›´æ¢æ ¸å¿ƒæ¶æ„ï¼**
"""
    return f"""ä½ æ˜¯ä¸€ä¸ªèµ„æ·±å·¥ç¨‹å¸ˆã€‚{base} è¦æ±‚ä»£ç å¥å£®ã€‚"""


def get_prompts_by_category(category):
    if category == "problem":
        return {
            "REVIEWER": """ä½ æ˜¯ä¸€ä¸ª OJ åˆ¤é¢˜ç³»ç»Ÿã€‚
**å¿…é¡»è¾“å‡º JSON**ã€‚
1. è‹¥ Runner æç¤º FAILï¼Œscore=0ã€‚
2. è‹¥ Runner æç¤º PASSï¼Œ**score å¿…é¡» >= 85**ã€‚
**æ‰€æœ‰åé¦ˆå¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚**
"""
        }
    return {
        "REVIEWER": """ä½ æ˜¯ä¸€ä¸ªæ¶æ„å®¡æŸ¥å‘˜ã€‚
**å¿…é¡»è¾“å‡º JSON**ã€‚
å¦‚æœä»£ç æœ‰åŠŸèƒ½é—®é¢˜ï¼Œscore < 60ã€‚
**æ‰€æœ‰åé¦ˆå¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚**
"""
    }


SYSTEM_TEST_EXTRACTOR = """æå–é¢˜ç›®ä¸­çš„æµ‹è¯•æ ·ä¾‹ä¸ºJSONåˆ—è¡¨ã€‚
æ ¼å¼: [{"input": "...", "output": "..."}, ...]

**é‡è¦åŸåˆ™ï¼ˆFormat Consistencyï¼‰**ï¼š
1. **ä¼˜å…ˆæå–**ï¼šå¦‚æœæœ‰æ˜ç¡®æ ·ä¾‹ï¼Œåªæå–æä¾›çš„ã€‚
2. **æ™ºèƒ½è¡¥å…¨**ï¼šå¦‚æœ**å¿…é¡»ç”Ÿæˆ**ï¼ˆç”¨æˆ·æœªæä¾›ï¼‰ï¼Œè¯·ç”Ÿæˆ 3-5 ä¸ªç”¨ä¾‹ï¼š
   - åŒ…å«ç®€å•æƒ…å†µï¼ˆSmall Caseï¼‰ã€‚
   - **å¿…é¡»åŒ…å«è¾¹ç•Œå¤§å€¼**ï¼ˆLarge/Edge Caseï¼Œå¦‚ N=æœ€å¤§å€¼ï¼‰ã€‚
   - ä¸¥æ ¼éµå®ˆé¢˜ç›® IO æ ¼å¼ã€‚
"""

SYSTEM_DEBUGGER = """ä½ æ˜¯ä¸€ä¸ªç®—æ³•è°ƒè¯•ä¸“å®¶ã€‚
è¯·åˆ†æä»£ç ä¸ºä½•æœªé€šè¿‡æµ‹è¯•ã€‚
è¯·ä»”ç»†å¯¹æ¯”ã€æœŸæœ›è¾“å‡ºã€‘å’Œã€å®é™…è¾“å‡ºã€‘çš„å·®å¼‚ï¼ˆå¦‚æ¢è¡Œç¬¦ã€ç©ºæ ¼ã€æ ‡ç‚¹ã€å¤šä½™çš„æç¤ºæ–‡å­—ï¼‰ã€‚
**å¿…é¡»ä½¿ç”¨ä¸­æ–‡ã€‚**
è¾“å‡ºJSON: {"analysis": "...", "suggestion": "..."}
"""

# --- V10.22: åŒè½¨å®¡æŸ¥ç³»ç»Ÿ ---

# è½¨é“ A: ç®—æ³•é¢˜å®¡è®¡å‘˜ (ä¸¥å‰ã€æ´ç™–ã€åå¹»è§‰)
SYSTEM_AUDITOR_ALGORITHM = """ä½ æ˜¯ä¸€ä¸ª ACM ç®—æ³•ç«èµ›åˆ¤é¢˜å®˜ã€‚
**ç°çŠ¶ï¼šä»£ç å·²é€šè¿‡æµ‹è¯•ï¼ˆåŠŸèƒ½æ­£ç¡®ï¼‰ã€‚**
ä»»åŠ¡ï¼šæ£€æŸ¥ç®—æ³•è§„èŒƒæ€§ã€‚

**å®¡æŸ¥æ ‡å‡†**ï¼š
1. **å¤æ‚åº¦**ï¼šæ˜¯å¦æ»¡è¶³æ—¶é—´/ç©ºé—´é™åˆ¶ï¼Ÿ(ä¸¥ç¦ O(2^N) é™¤é N å¾ˆå°)ã€‚
2. **IO è§„èŒƒ**ï¼šæ˜¯å¦æœ‰å¤šä½™çš„è¾“å‡ºï¼Ÿï¼ˆå¿…é¡»çº¯å‡€è¾“å‡ºï¼‰ã€‚
3. **åå¹»è§‰**ï¼šåªçœ‹å½“å‰ä»£ç ï¼Œä¸è¦å¤è¯»å†å²é”™è¯¯ã€‚å¦‚æœä»£ç æ˜¯å¾ªç¯ï¼Œä¸¥ç¦è¯´æ˜¯é€’å½’ã€‚

è¾“å‡ºJSON: {"score": <85-100>, "pass": true, "critique": "..."}
"""

# è½¨é“ B: å·¥ç¨‹é¡¹ç›®å®¡è®¡å‘˜ (å®½å®¹ã€æ³¨é‡ä½“éªŒã€æ¶æ„)
SYSTEM_AUDITOR_PROJECT = """ä½ æ˜¯ä¸€ä¸ªèµ„æ·±è½¯ä»¶æ¶æ„å¸ˆã€‚
**ç°çŠ¶ï¼šä»£ç å·²é€šè¿‡æµ‹è¯•ï¼ˆæˆ–æ— éœ€æµ‹è¯•ï¼‰ã€‚**
ä»»åŠ¡ï¼šæ£€æŸ¥å·¥ç¨‹è´¨é‡å’Œç”¨æˆ·ä½“éªŒã€‚

**å®¡æŸ¥æ ‡å‡†**ï¼š
1. **ç”¨æˆ·ä½“éªŒ (UX)**ï¼šæ˜¯å¦æœ‰æ¸…æ™°çš„æç¤ºæŒ‡å¼•ï¼ˆå¦‚ "æŒ‰å›è½¦å¼€å§‹"ï¼‰ï¼Ÿäº¤äº’æ˜¯å¦æµç•…ï¼Ÿ
2. **ä»£ç ç»“æ„**ï¼šæ˜¯å¦æ¨¡å—åŒ–ï¼ˆå‡½æ•°/ç±»åˆ†ç¦»ï¼‰ï¼Ÿå˜é‡å‘½åæ˜¯å¦è¯­ä¹‰åŒ–ï¼Ÿ
3. **å…¼å®¹æ€§**ï¼šæ˜¯å¦è€ƒè™‘äº†ä¸åŒç¯å¢ƒçš„è¿è¡Œï¼ˆå¦‚è·¨å¹³å°è¾“å…¥å¤„ç†ï¼‰ï¼Ÿ
4. **æ³¨æ„**ï¼šå¯¹äºå·¥ç¨‹/æ¸¸æˆç±»ä»»åŠ¡ï¼Œ**å…è®¸å¹¶é¼“åŠ±**ä½¿ç”¨ `input()` è¿›è¡Œäº¤äº’ï¼Œ**ä¸è¦æ±‚**é™é»˜è¾“å‡ºã€‚

è¾“å‡ºJSON: {"score": <85-100>, "pass": true, "critique": "..."}
"""

SYSTEM_IMPROVER = """ä½ æ˜¯ä¸€ä¸ªèµ„æ·±æŠ€æœ¯å¯¼å¸ˆã€‚
ä»£ç å·²ç»å®Œç¾é€šè¿‡æµ‹è¯•ã€‚ç°åœ¨è¯·ç»™å‡º **é”¦ä¸Šæ·»èŠ±** çš„å»ºè®®ã€‚
è¾“å‡ºJSON: {"critique": "Markdownå»ºè®®"}
"""

SYSTEM_VISUALIZER = """ç”Ÿæˆ Mermaid JS æµç¨‹å›¾ (graph TD)ã€‚
1. èŠ‚ç‚¹æè¿°å¿…é¡»ä½¿ç”¨**ä¸­æ–‡ç®€è¿°**ï¼Œä¸è¦åŒ…å«ä»£ç ç¬¦å·ã€‚
2. èŠ‚ç‚¹IDä½¿ç”¨ A, B, C...
è¾“å‡ºJSON:
{
    "nodes": [{"id": "A", "text": "å¼€å§‹"}, ...],
    "edges": [{"from": "A", "to": "B", "label": "å¯é€‰"}, ...]
}
"""


# ==========================================
# 2. å·¥å…·å‡½æ•°
# ==========================================

async def call_llm(system_prompt, user_content, json_mode=False, temperature=1.0):
    try:
        response = await client.chat.completions.create(
            model="deepseek-chat",
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}],
            response_format={"type": "json_object"} if json_mode else {"type": "text"},
            temperature=temperature,
            timeout=60
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f">> LLM Error: {e}")
        return "{}" if json_mode else f"Error: {str(e)}"


async def call_llm_direct(messages, json_mode=False, temperature=1.0):
    try:
        response = await client.chat.completions.create(
            model="deepseek-chat",
            messages=messages,
            response_format={"type": "json_object"} if json_mode else {"type": "text"},
            temperature=temperature,
            timeout=60
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f">> LLM Error: {e}")
        return "{}" if json_mode else f"Error: {str(e)}"


async def call_llm_stream(system_prompt, messages_history, temperature=1.0):
    try:
        full_messages = [{"role": "system", "content": system_prompt}] + messages_history
        stream = await client.chat.completions.create(
            model="deepseek-chat", messages=full_messages, stream=True, temperature=temperature, timeout=60
        )
        full_content = ""
        async for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content
                full_content += content
                yield {"phase": "code_chunk", "content": content}
        yield {"phase": "stream_finished", "full_content": full_content}
    except Exception as e:
        yield {"phase": "log", "content": f"âš ï¸ ç½‘ç»œä¸­æ–­: {str(e)[:50]}..."}


def clean_json_text(text):
    if not text: return "{}"
    text = re.sub(r"```json", "", text, flags=re.IGNORECASE)
    text = re.sub(r"```", "", text)
    return text.strip()


def detect_language(text):
    if "```python" in text or "def " in text: return "python"
    return "cpp"


def extract_code_content(text):
    pattern = r"```(?:\w+)?\n([\s\S]*?)(?:```|$)"
    matches = re.findall(pattern, text, re.DOTALL)
    if matches:
        valid = [m.strip() for m in matches if len(m.strip()) > 20]
        for m in valid:
            if re.search(r"int\s+main", m): return m
        for m in valid:
            if re.search(r"if\s+__name__", m): return m
        if valid: return valid[-1]

    cpp_match = re.search(r"(#include\s*<|int\s+main\s*\()", text)
    if cpp_match:
        return text[cpp_match.start():].strip()
    py_match = re.search(r"(def\s+solution|if\s+__name__\s*==|import\s+sys)", text)
    if py_match:
        return text[py_match.start():].strip()
    return ""


def detect_code_block(text):
    has_markdown = "```" in text
    has_cpp = bool(re.search(r"(#include|int\s+main\s*\()", text))
    has_py = bool(re.search(r"(def\s+|class\s+|import\s+)", text))
    return has_markdown or has_cpp or has_py


def generate_mermaid_from_json(json_str):
    try:
        data = json.loads(clean_json_text(json_str))
        nodes = data.get("nodes", [])
        edges = data.get("edges", [])
        if not nodes: return "graph TD\nA(æš‚æ— æ•°æ®)"
        mermaid_lines = ["graph TD"]
        for node in nodes:
            nid = node.get("id", "A").replace(" ", "")
            raw_text = node.get("text", "èŠ‚ç‚¹")
            safe_text = re.sub(r"[^\u4e00-\u9fa5a-zA-Z0-9]", "", raw_text)
            if not safe_text: safe_text = "æ“ä½œ"
            mermaid_lines.append(f'{nid}("{safe_text}")')
        for edge in edges:
            frm = edge.get("from").replace(" ", "")
            to = edge.get("to").replace(" ", "")
            label = edge.get("label", "")
            if label:
                safe_label = re.sub(r"[^\u4e00-\u9fa5a-zA-Z0-9]", "", label)
                mermaid_lines.append(f'{frm} -- "{safe_label}" --> {to}')
            else:
                mermaid_lines.append(f'{frm} --> {to}')
        return "\n".join(mermaid_lines)
    except Exception as e:
        return "graph TD\nA(å›¾è¡¨ç”Ÿæˆå¤±è´¥)"


def sanitize_json(data, raw_text=""):
    if not isinstance(data, dict):
        return {"score": 0, "pass": False, "critique": f"è§£æå¼‚å¸¸: {raw_text[:100]}..."}
    critique = str(data.get("critique", ""))
    if not critique or len(critique) < 5:
        critique = str(data.get("suggestion", "")) or "ä»£ç ç¬¦åˆè§„èŒƒã€‚"
    return {
        "score": int(data.get("score", 0)),
        "pass": bool(data.get("pass", False)),
        "critique": critique
    }


def validate_test_cases(raw_cases):
    valid_cases = []
    if isinstance(raw_cases, dict):
        for val in raw_cases.values():
            if isinstance(val, list):
                raw_cases = val
                break
    if not isinstance(raw_cases, list): return []
    for item in raw_cases:
        if isinstance(item, str):
            try:
                item = json.loads(item.replace("'", '"'))
            except:
                pass
        if isinstance(item, dict) and "input" in item:
            valid_cases.append(item)
    return valid_cases


def normalize_output(text):
    if not text: return ""
    text = text.replace('\r\n', '\n').replace('\r', '\n')
    lines = [line.rstrip() for line in text.strip().split('\n')]
    return '\n'.join(lines).strip()


def run_code(code_str, language, input_str):
    with tempfile.NamedTemporaryFile(mode='w', suffix=f'.{language.replace("python", "py")}', delete=False,
                                     encoding='utf-8') as tmp:
        tmp.write(code_str)
        tmp_path = tmp.name
    try:
        if language == "python":
            cmd = [sys.executable, tmp_path]
        else:  # cpp
            exe = tmp_path + ".exe"
            compile_res = subprocess.run(
                ["g++", tmp_path, "-o", exe],
                capture_output=True
            )
            if compile_res.returncode != 0:
                err_msg = compile_res.stderr.decode(errors='replace')
                return "", f"Compile Error: {err_msg}"
            cmd = [exe]

        result = subprocess.run(
            cmd,
            input=input_str.encode(),
            capture_output=True,
            timeout=5
        )

        stdout = result.stdout.decode(errors='replace')
        stderr = result.stderr.decode(errors='replace')
        return normalize_output(stdout), normalize_output(stderr)

    except subprocess.TimeoutExpired:
        return "", "Timeout"
    except Exception as e:
        return "", str(e)
    finally:
        try:
            os.remove(tmp_path)
        except:
            pass
        if language == "cpp" and os.path.exists(tmp_path + ".exe"):
            try:
                os.remove(tmp_path + ".exe")
            except:
                pass


# ==========================================
# 3. æ ¸å¿ƒå·¥ä½œæµ
# ==========================================

async def workflow_orchestrator(user_task: str):
    def log(msg):
        return {"phase": "log", "content": msg}

    yield log("æ ¸å¿ƒåˆå§‹åŒ–...")

    current_code_raw = ""
    test_cases = []
    chat_history = []
    target_language = "cpp"
    approved_design = None
    previous_score = 0
    pivot_recommendation = None

    # 1. æ„å›¾è¯†åˆ«
    yield log("åˆ†æä»»åŠ¡æ„å›¾...")
    task_category = "task"
    try:
        cls_res = await call_llm(SYSTEM_CLASSIFIER, user_task, json_mode=True)
        cls_data = json.loads(clean_json_text(cls_res))
        task_category = cls_data.get("type", "task")
        target_language = cls_data.get("language", "cpp")

        if detect_code_block(user_task):
            extracted = extract_code_content(user_task)
            if len(extracted) > 20:
                current_code_raw = extracted
                task_category = "code"
                target_language = detect_language(current_code_raw)
                yield log("âš¡ æ£€æµ‹åˆ°ç”¨æˆ·ä»£ç ï¼Œè¿›å…¥æ··åˆæ¨¡å¼...")
    except:
        pass

    yield log(f"æ¨¡å¼è¯†åˆ«: {task_category.upper()} | ç›®æ ‡è¯­è¨€: {target_language.upper()}")
    STRATEGIES = get_prompts_by_category(task_category)

    # 2. æå–æ ·ä¾‹
    if task_category != "task":
        try:
            cases_str = await call_llm(SYSTEM_TEST_EXTRACTOR, user_task, json_mode=True)
            raw_cases = json.loads(clean_json_text(cases_str))
            test_cases = validate_test_cases(raw_cases)
            if test_cases: yield log(f"æå–åˆ° {len(test_cases)} ä¸ªæµ‹è¯•æ ·ä¾‹ã€‚")
        except:
            pass

    # 3. æ¶æ„è®¾è®¡ (Strategic Pivot)
    if current_code_raw:
        yield log("ğŸ” åˆ†æç”¨æˆ·ä»£ç æ¶æ„...")
        try:
            rev_res = await call_llm(SYSTEM_REVERSE_ARCHITECT, current_code_raw, json_mode=True)
            user_design = json.loads(clean_json_text(rev_res))

            yield log("âš–ï¸ è¯„ä¼°ç®—æ³•å¯è¡Œæ€§...")
            feasibility_res = await call_llm(SYSTEM_FEASIBILITY_ANALYST, f"é¢˜ç›®:{user_task}\nå½“å‰è®¾è®¡:{rev_res}",
                                             json_mode=True)
            feasibility = json.loads(clean_json_text(feasibility_res))

            if feasibility.get("pass"):
                approved_design = user_design
                yield log(f"âœ… æ€è·¯å¯è¡Œ: {user_design.get('algorithm')}")
            else:
                yield log(f"âŒ æ€è·¯é”™è¯¯: {feasibility.get('reason')}")
                pivot_recommendation = feasibility.get("recommendation")
                yield {
                    "phase": "feasibility_alert",
                    "content": {
                        "reason": feasibility.get("reason"),
                        "recommendation": pivot_recommendation
                    }
                }
                yield log(f"ğŸ”„ æˆ˜ç•¥è½¬å‹: {pivot_recommendation}")
                current_code_raw = ""
        except Exception as e:
            yield log(f"æ¶æ„åˆ†æå¼‚å¸¸: {e}ï¼Œå°è¯•ç›´æ¥ä¿®å¤ã€‚")

    if (not current_code_raw) and task_category in ["problem", "task"]:
        yield log("ğŸ“ æ­£åœ¨è§„åˆ’æ¶æ„æ–¹æ¡ˆ...")
        try:
            for _ in range(2):
                arch_prompt = get_architect_prompt(pivot_recommendation)
                design_res = await call_llm(arch_prompt, user_task, json_mode=True)

                design_json = json.loads(clean_json_text(design_res))
                review_res = await call_llm(SYSTEM_ARCHITECT_REVIEWER, f"é¢˜ç›®:{user_task}\næ–¹æ¡ˆ:{design_res}",
                                            json_mode=True)
                review_json = json.loads(clean_json_text(review_res))
                if review_json.get("pass"):
                    approved_design = design_json
                    yield log(f"æ–°æ¶æ„é”å®š: {design_json.get('algorithm')}")
                    break
        except:
            pass

    # 4. ä»£ç ç”Ÿæˆ
    if current_code_raw:
        target_language = detect_language(current_code_raw)
        chat_history.append(
            {"role": "user", "content": f"é¢˜ç›®/éœ€æ±‚å¦‚ä¸‹ï¼ŒåŒ…å«æˆ‘çš„ä»£ç :\n{user_task}\n\nè¯·å¸®æˆ‘æ£€æŸ¥å¹¶å®Œå–„ä»£ç ã€‚"})
        wrapped_code = f"```{target_language}\n{current_code_raw}\n```"
        chat_history.append({"role": "assistant", "content": wrapped_code})
        yield {"phase": "final_code", "content": {"code": wrapped_code}}
        yield log("å·²è£…è½½ä»£ç ï¼Œå¼€å§‹å®¡æŸ¥...")
    else:
        yield log("ğŸ—ï¸ æ„å»ºå·¥ç¨‹ä»£ç ...")
        coder_sys_prompt = get_coder_prompt(task_category, approved_design, language=target_language)
        design_str = f"\nã€å·²é”å®šçš„æ¶æ„æ–¹æ¡ˆã€‘\n{json.dumps(approved_design, ensure_ascii=False)}" if approved_design else ""
        chat_history.append({"role": "user", "content": f"éœ€æ±‚: {user_task}{design_str}"})
        async for packet in call_llm_stream(coder_sys_prompt, chat_history):
            if packet["phase"] == "code_chunk":
                yield packet
            elif packet["phase"] == "stream_finished":
                current_code_raw = packet["full_content"]
                chat_history.append({"role": "assistant", "content": current_code_raw})

    # 5. å¾ªç¯å®¡æŸ¥
    max_retries = 4
    final_review = None

    for attempt in range(max_retries + 1):
        round_num = attempt + 1
        current_lang = detect_language(current_code_raw)
        pure_code = extract_code_content(current_code_raw)

        if not pure_code:
            yield log("âš ï¸ ä»£ç æå–å¤±è´¥ï¼Œé‡è¯•...")
            chat_history.append({"role": "user", "content": "é”™è¯¯ï¼šæœªæ£€æµ‹åˆ°ä»£ç å—ã€‚è¯·è¾“å‡º ```cpp æˆ– ```pythonã€‚"})
            yield {"phase": "clear_code", "content": ""}
            async for packet in call_llm_stream(
                    get_coder_prompt(task_category, approved_design, language=target_language), chat_history):
                if packet["phase"] == "code_chunk":
                    yield packet
                elif packet["phase"] == "stream_finished":
                    current_code_raw = packet["full_content"]
                    chat_history.append({"role": "assistant", "content": current_code_raw})
            continue

        yield log(f"æ‰§è¡Œç¬¬ {round_num} è½®æµ‹è¯• ({current_lang})...")

        run_passed = True
        run_report = ""
        if test_cases and current_lang != "unknown" and task_category != "task":
            for idx, case in enumerate(test_cases):
                inp, exp = str(case.get("input", "")), normalize_output(str(case.get("output", "")))
                act, err = run_code(pure_code, current_lang, inp)
                if err:
                    run_passed = False
                    run_report += f"[Case {idx + 1} Error] {err}\n"
                    yield log(f"âŒ æ ·ä¾‹ {idx + 1} æŠ¥é”™")
                elif act != exp:
                    run_passed = False
                    run_report += f"[Case {idx + 1} Fail]\nExpected:\n{exp[:150]}\nActual:\n{act[:150]}\n"
                    yield log(f"âŒ æ ·ä¾‹ {idx + 1} ä¸åŒ¹é…")
                else:
                    yield log(f"âœ… æ ·ä¾‹ {idx + 1} é€šè¿‡")
        else:
            if task_category == "task":
                run_report = "ä»»åŠ¡æ¨¡å¼ï¼šè·³è¿‡è‡ªåŠ¨æµ‹è¯•ã€‚"
            else:
                run_report = "æ— æµ‹è¯•æ ·ä¾‹ã€‚"

        yield log("ğŸ” ä¸“å®¶å®¡æŸ¥ä¸­...")
        review_json = {}
        try:
            if not run_passed:
                debug_input = f"""ä»£ç :
{pure_code}

é”™è¯¯:
{run_report}

éœ€æ±‚: {user_task}

ã€æ³¨æ„ã€‘è¯·ä»”ç»†å¯¹æ¯” Expected å’Œ Actual çš„å·®å¼‚ï¼ˆå¦‚ç©ºæ ¼ã€æ¢è¡Œã€å¤šä½™çš„æç¤ºæ–‡å­—ï¼‰ã€‚"""
                debug_resp = await call_llm(SYSTEM_DEBUGGER, debug_input, json_mode=True)
                debug_json = json.loads(clean_json_text(debug_resp))
                review_json = {
                    "pass": False, "score": 40,
                    "critique": f"**æ•…éšœåˆ†æ**: {debug_json.get('analysis')}\n\n**ä¿®å¤æ–¹æ¡ˆ**: {debug_json.get('suggestion')}"
                }
            else:
                design_context = json.dumps(approved_design, ensure_ascii=False) if approved_design else "æ— ï¼ˆè‡ªç”±å‘æŒ¥ï¼‰"
                audit_input = f"""
ã€åŸå§‹éœ€æ±‚ã€‘:
{user_task}

ã€å·²ç¡®è®¤çš„æ¶æ„è“å›¾ã€‘:
{design_context}

ã€å¾…å®¡æŸ¥ä»£ç ã€‘:
{pure_code}

è¯·æ ¹æ®ä¸Šè¿°è“å›¾å’Œéœ€æ±‚ï¼Œå¯¹ä»£ç è¿›è¡Œè§„èŒƒæ€§å®¡è®¡ã€‚
"""
                # V10.22 æ ¸å¿ƒ: å®¡è®¡åˆ†æµ (Audit Forking)
                selected_auditor = SYSTEM_AUDITOR_PROJECT if task_category == "task" else SYSTEM_AUDITOR_ALGORITHM

                audit_messages = [
                    {"role": "system", "content": selected_auditor},
                    {"role": "user", "content": audit_input}
                ]
                audit_resp = await call_llm_direct(audit_messages, json_mode=True)

                raw_json = json.loads(clean_json_text(audit_resp))
                review_json = sanitize_json(raw_json, raw_text=audit_resp)
                review_json["pass"] = True

                current_score = review_json.get("score", 0)
                if current_score >= 90 and len(review_json.get("critique", "")) < 15: review_json["score"] = 95
                if current_score == previous_score and current_score >= 85: review_json["score"] = 95
                previous_score = current_score
        except Exception as e:
            review_json = {"pass": False, "score": 0, "critique": f"å®¡æŸ¥å¼‚å¸¸: {str(e)}"}

        yield {
            "phase": "iteration",
            "data": {"round": round_num, "code": current_code_raw, "review": review_json}
        }

        # ä¿®å¤é€»è¾‘ï¼šå¿…é¡» run_passed ä¸”æ˜¯é¦–æ¬¡ï¼Œæ‰å¼ºåˆ¶æ‰“ç£¨
        is_user_first_run = (task_category == 'code' and attempt == 0 and run_passed)

        if review_json["score"] >= 95 and run_passed and not is_user_first_run:
            yield log("ä»£ç å®Œç¾é€šè¿‡ã€‚âœ¨")
            final_review = review_json
            break
        else:
            if attempt < max_retries:
                effective_score = 90 if is_user_first_run else review_json['score']
                yield log(f"å¾—åˆ† {effective_score}ï¼Œè§¦å‘{'æ·±åº¦æ‰“ç£¨' if is_user_first_run else 'ä¿®æ­£'}...")

                fix_temp = 0.7 if not run_passed else 0.0
                refine_instruction = ""

                if is_user_first_run:
                    refine_instruction = f"ä»£ç åŠŸèƒ½å·²é€šè¿‡æµ‹è¯•ã€‚ç°åœ¨è¯·**ä¼˜åŒ–ä»£ç é£æ ¼**ï¼š\n1. è§„èŒƒå˜é‡å‘½åã€‚\n2. æ·»åŠ è¯¦ç»†ä¸­æ–‡æ³¨é‡Šã€‚\n3. ä¼˜åŒ–ä»£ç ç»“æ„ï¼ˆä¿æŒåŠŸèƒ½ä¸å˜ï¼‰ã€‚\né—®é¢˜å‚è€ƒ: {review_json['critique']}"
                else:
                    refine_instruction = f"é—®é¢˜:\n{review_json['critique']}\n\næŠ¥å‘Š:\n{run_report}\n\nè¯·ä¿®æ”¹ä»£ç ã€‚ä¿æŒä½¿ç”¨ {target_language}ã€‚"

                if approved_design: refine_instruction += f"\n\n**è­¦æŠ¥**ï¼šä¸¥ç¦æ›´æ”¹ã€{approved_design.get('algorithm')}ã€‘ç®—æ³•æ¡†æ¶ï¼"

                chat_history.append({"role": "user", "content": refine_instruction})
                yield {"phase": "clear_code", "content": ""}
                async for packet in call_llm_stream(
                        get_coder_prompt(task_category, approved_design, language=target_language), chat_history,
                        temperature=fix_temp):
                    if packet["phase"] == "code_chunk":
                        yield packet
                    elif packet["phase"] == "stream_finished":
                        current_code_raw = packet["full_content"]
                        chat_history.append({"role": "assistant", "content": current_code_raw})
            else:
                yield log("å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ã€‚")
                final_review = review_json

    if not run_passed:
        yield log("âš ï¸ ç†”æ–­ï¼šä»£ç å­˜åœ¨åŠŸèƒ½æ€§é”™è¯¯ã€‚")
        yield {"phase": "final_code_update", "content": {"review": final_review}}
        yield {"phase": "failure_report", "content": {"message": "æŠ±æ­‰ï¼Œä»£ç å¤šæ¬¡ä¿®å¤åä»æ— æ³•é€šè¿‡æµ‹è¯•ã€‚",
                                                      "issues": run_report + "\n" + final_review.get('critique', '')}}
        yield {"phase": "done", "content": ""}
        return

    yield log("ç”Ÿæˆè¿›é˜¶å»ºè®®...")
    try:
        improver_res = await call_llm(SYSTEM_IMPROVER, f"ä»£ç :\n{extract_code_content(current_code_raw)}",
                                      json_mode=True)
        improver_json = json.loads(clean_json_text(improver_res))
        final_review["critique"] = improver_json.get("critique", "æ— å»ºè®®")
        final_review["score"] = 100
    except:
        pass

    yield {"phase": "final_code_update", "content": {"review": final_review}}

    yield log("ç”Ÿæˆæ·±åº¦è§£ææŠ¥å‘Š...")
    final_pure_code = extract_code_content(current_code_raw)

    async def task_viz():
        json_str = await call_llm(SYSTEM_VISUALIZER, f"ä»£ç :\n{final_pure_code}", json_mode=True, temperature=0.0)
        return generate_mermaid_from_json(json_str)

    async def task_exp():
        prompt = get_explainer_prompt(task_category)
        return await call_llm(prompt, f"ä»»åŠ¡:{user_task}\nä»£ç :{current_code_raw}", json_mode=True, temperature=0.4)

    try:
        results = await asyncio.gather(task_viz(), task_exp(), return_exceptions=True)
        viz_res = results[0]
        exp_res_raw = results[1]

        if isinstance(viz_res, Exception):
            yield log(f"Viz Error: {viz_res}")
        else:
            yield {"phase": "diagram", "content": viz_res.strip()}

        if isinstance(exp_res_raw, Exception):
            yield log(f"Exp Error: {exp_res_raw}")
        else:
            try:
                data = json.loads(clean_json_text(exp_res_raw))
                yield {"phase": "explanation", "content": data}
            except Exception as e:
                fallback_data = {
                    "simple": "è‡ªåŠ¨è§£æç»“æ„å¼‚å¸¸ï¼Œä»¥ä¸‹ä¸ºåŸå§‹å†…å®¹ï¼š\n\n" + str(exp_res_raw),
                    "academic": "ï¼ˆè§£æå¤±è´¥ï¼‰"
                }
                yield {"phase": "explanation", "content": fallback_data}

    except Exception as e:
        yield log(f"Final Report Error: {e}")

    yield log("ä»»åŠ¡å®Œæˆã€‚")
    yield {"phase": "done", "content": ""}